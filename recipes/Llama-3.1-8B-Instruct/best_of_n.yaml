# refer to src/sal/config.py for more options
model_path: meta-llama/Llama-3.1-8B-Instruct
approach: best_of_n
search_batch_size: 25
sort_completed: true
filter_duplicates: true
seed: 0
# specify n
# specify score_method: default is prm
#   if 'conf', specify conf_strategy: default is probs_mean